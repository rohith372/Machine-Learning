# -*- coding: utf-8 -*-
"""CustomerChurn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jniHM6Urr-ACDQC95F7evTx5Gb0r7_Px
"""

# Importing the required Libraries
import numpy as np
import pandas as pd
import sklearn
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# Read the data and see number of columns and rows
df = pd.read_csv("/content/drive/MyDrive/churn.csv")
df.shape

# To see all column names
df.columns.values

# To check for NA or missing values
df.isna().sum()

# To show some statistics
df.describe()

# To get Customer Churn count
df['Churn'].value_counts()

# Visualize the count of customer churn
sns.countplot(df['Churn'])

# To see the percentage of customers that are leaving
numRetained = df[df.Churn == 'No'].shape[0]
numChurned = df[df.Churn == 'Yes'].shape[0]

# print the percentage of customers that stayed
print(numRetained/(numRetained + numChurned) * 100,'% of customers stayed in the company')
# peint the percentage of customers that left
print(numChurned/(numRetained + numChurned) * 100, '% of customers left with the company')

# Visualize the churn count for both males and females
sns.countplot(x ='gender', hue='Churn', data=df)

# Visualize the churn count for the internet service
sns.countplot(x='InternetService', hue='Churn', data=df)

# Visualize numeric data
numericFeatures = ['tenure', 'MonthlyCharges']
fig, ax = plt.subplots(1,2, figsize=(28, 8))
df[df.Churn == "No"][numericFeatures].hist(bins=20, color='blue', alpha=0.5, ax=ax)
df[df.Churn == "Yes"][numericFeatures].hist(bins=20, color='orange', alpha=0.5, ax=ax)

# Remove unnecessary columns
cleanDF = df.drop('customerID', axis=1)

#Convert all the non-numeric columns to numeric
for column in cleanDF.columns:
  if cleanDF[column].dtype == np.number:
    continue
  cleanDF[column] = LabelEncoder().fit_transform(cleanDF[column])

# Show data types
cleanDF.dtypes

# Scale the data
x = cleanDF.drop('Churn', axis=1)
y = cleanDF['Churn']
x = StandardScaler().fit_transform(x)

# Split the data
xtrain, xtest, ytrain, ytest = train_test_split(x,y, test_size=0.2, random_state=42)

# Create and train the model
model = LogisticRegression()
# Train the model
model.fit(xtrain, ytrain)

predictions = model.predict(xtest)

# print the predictions
print(predictions)

# Finally check the precision, recall and f1-score
print(classification_report(ytest, predictions))